#以多组参数并行执行函数

**任务**

需要用不同的多组参数来同时执行一个函数（`这个函数可能是“I/0绑定的”,即它需要花费相当多的时间来完成输入输出操作；若非如些，同时执行没有多大用处`）。

**解决方案**

我们对于每组参数使用一个线程。但为了获得好的性能，最好将线程的使用限定于一个有限的线程池：

```Python
# -*- coding:utf-8 -*-
import threading,time,Queue
class MultiThread(object):
    def __init__(self,function,argsVector,
                 maxThreads=5,queue_results=False):
        self._function = function
        self._lock = threading.Lock()
        self._nextArgs = iter(argsVector).next
        self._threadPool = [threading.Thread(target=self._doSome) 
                            for i in range(maxThreads)]
        if queue_results:
            self._queue = Queue.Queue()
        else:
            self._queue = None

    def _doSome(self):
        while True:
            self._lock.acquire()
            try:
                try:
                    args = self._nextArgs()
                except StopIteration:
                    break
            finally:
                self._lock.release()
            result = self._function(args)
            if self._queue is not None:
                self._queue.put((args,result))
    def get(self,*a,**kw):
        if self._queue is not None:
            return self._queue.get(*a,**kw)
        else:
            raise ValueError,'Not queueing results'
    def start(self):
        for thread in self._threadPool:
            time.sleep(0)
            thread.start()
    def join(self,timeout=None):
        for thread in self._threadPool:
            thread.join(timeout)

if __name__ == '__main__':
    import random
    def recite_n_times_table(n):
        for i in range(2,11):
            print "%d * %d = %d" %(n,i,n*i)
            time.sleep(0.3 + 0.3 * random.random())
    mt = MultiThread(recite_n_times_table,range(2,11))
    mt.start()
    mt.join()
    print "Well done kids!"
```

**讨论**

本节的MultiThread类提供了一个简单的方法，以多组参数和一个有限的线程池来并行地执行函数。另外，作为一个选项，还可以要求把函数调用的结果放入队列，以方便获取，默认情况下结果是被丢弃的。

像Python的通常做法一样，这个模块也可以被作为独立的主脚本运行，这个它只是对自身功能的一个简单展示和自我测试。

而这个类在真实的应用中则可能涉及与I/0紧密的函数，那意味着函数会花相当多的时间执行I/0操作。如果一个函数是与CPU活动紧密关联的，那意味着该函数大部分时间是运行在CPU计算上，你简单地一个接一个地完成计算任务，反而可能比并行方式的总体性能要高。对于Python而言，即使把你的程序放在多处理器计算机上运行，其表现仍然符合上面提到的观察结果，这是因为Python使用了GIL,`纯Python代码不能在同一时刻运行在不同的CPU上`。

`输入输出操作释放了GIL，任何基于C的执行大量计算而不用回调Python代码的扩展也会（应该）释放GIL`。所以，并行执行是有可能提速的，但仅限于有不少I/0操作或者涉及一个合适的基于C的扩展的程序，对于执行密集计算的Python代码则并不适合用。（基于Python的不同虚拟机的实现，如Jython，运行在JVM[java虚拟机]之上，或者IronPython，运行在Microsoft的.NET平台上，它们理所当然地不受限制：这些观察仅仅适用于Cpython实现。）
